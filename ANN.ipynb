{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: [***Datasets***](https://keras.io/api/datasets/) in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is one of the handwriting digits of \u001b[1m6:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load MNIST dataset \n",
    "(x_train , y_train), (x_test , y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Standardize the data to have a spread of 1\n",
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "\n",
    "# Pick a random integer/digit within the training set\n",
    "random_digit = np.random.randint(0, len(x_train)-1)\n",
    "\n",
    "# Plot the image of this digit for visualization and comparison after training\n",
    "print(\"\\nThis is one of the handwriting digits of \\033[1m\"+str(y_train[random_digit])+\":\\n\")\n",
    "plt.imshow(x_train[random_digit])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-Connected ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Class: [***Sequential***](https://keras.io/api/models/sequential/) in Keras\n",
    "\n",
    "Summary Method: [***Summary***](https://keras.io/api/models/model/) in Keras\n",
    "\n",
    "\n",
    "#### Layers\n",
    "\n",
    "Layers  Class: [***Layers***](https://keras.io/api/layers/) in Keras\n",
    "\n",
    "Flatten Layer: [***Flatten layer***](https://keras.io/api/layers/reshaping_layers/flatten/) in Keras\n",
    "\n",
    "Dense Layer: [***Dense layer***](https://keras.io/api/layers/core_layers/dense/) in Keras\n",
    "\n",
    "\n",
    "#### Layer Activation\n",
    "\n",
    "Layer Activation: [***Layer activation functions***](https://keras.io/api/layers/activations/) in Keras\n",
    "\n",
    "ReLU function: [***ReLU***](https://keras.io/api/layers/activations/) in Keras\n",
    "\n",
    "Softmax function: [***Softmax***](https://keras.io/api/layers/activations/) in Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                9420      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 9,550\n",
      "Trainable params: 9,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the network\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(12, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Tensor' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-17403e296a96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Plot the predicted probability distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'Tensor' has no len()"
     ]
    }
   ],
   "source": [
    "# Calculate the model prediction \"before\" training\n",
    "pred = model(np.array(x_train[random_digit:random_digit+1], dtype=np.float32))\n",
    "\n",
    "# Plot the predicted probability distribution\n",
    "label = np.arange(0, len(pred[0]))\n",
    "plt.bar(label, pred[0]) \n",
    "plt.xticks(label) \n",
    "plt.xlabel('Digit Classification')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Method: [***Compile***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Fit Method: [***Fit***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Metrics arguments: [***Metrics***](https://keras.io/api/metrics/) in Keras\n",
    "\n",
    "Accuracy arguments: [***Accuracy***](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class) in Keras\n",
    "\n",
    "Losses classes: [***Losses***](https://keras.io/api/losses/) in Keras\n",
    "\n",
    "Sparse Categorical Crossentropy class: [***SparseCategoricalCrossentropy***](https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class) in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4574 - acc: 0.8700 - val_loss: 0.2746 - val_acc: 0.9227\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2628 - acc: 0.9245 - val_loss: 0.2396 - val_acc: 0.9313\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2335 - acc: 0.9336 - val_loss: 0.2264 - val_acc: 0.9353\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2161 - acc: 0.9385 - val_loss: 0.2141 - val_acc: 0.9372\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2031 - acc: 0.9426 - val_loss: 0.2033 - val_acc: 0.9412\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1941 - acc: 0.9452 - val_loss: 0.2022 - val_acc: 0.9421\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1871 - acc: 0.9461 - val_loss: 0.1962 - val_acc: 0.9431\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1824 - acc: 0.9476 - val_loss: 0.1920 - val_acc: 0.9450\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1764 - acc: 0.9497 - val_loss: 0.1945 - val_acc: 0.9418\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1728 - acc: 0.9508 - val_loss: 0.1924 - val_acc: 0.9417\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1689 - acc: 0.9520 - val_loss: 0.1873 - val_acc: 0.9442\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1661 - acc: 0.9524 - val_loss: 0.1919 - val_acc: 0.9428\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1640 - acc: 0.9535 - val_loss: 0.1916 - val_acc: 0.9444\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1612 - acc: 0.9532 - val_loss: 0.1947 - val_acc: 0.9429\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1586 - acc: 0.9543 - val_loss: 0.1941 - val_acc: 0.9445\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1569 - acc: 0.9549 - val_loss: 0.1891 - val_acc: 0.9451\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1542 - acc: 0.9556 - val_loss: 0.1904 - val_acc: 0.9452\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1529 - acc: 0.9554 - val_loss: 0.1964 - val_acc: 0.9436\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1516 - acc: 0.9559 - val_loss: 0.1951 - val_acc: 0.9438\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1506 - acc: 0.9562 - val_loss: 0.1859 - val_acc: 0.9461\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1493 - acc: 0.9566 - val_loss: 0.1897 - val_acc: 0.9462\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1469 - acc: 0.9576 - val_loss: 0.1898 - val_acc: 0.9463\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1456 - acc: 0.9578 - val_loss: 0.1925 - val_acc: 0.9442\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1451 - acc: 0.9580 - val_loss: 0.1939 - val_acc: 0.9432\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1440 - acc: 0.9575 - val_loss: 0.1901 - val_acc: 0.9469\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1427 - acc: 0.9586 - val_loss: 0.1921 - val_acc: 0.9453\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1416 - acc: 0.9591 - val_loss: 0.1930 - val_acc: 0.9458\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1409 - acc: 0.9590 - val_loss: 0.1921 - val_acc: 0.9448\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1397 - acc: 0.9587 - val_loss: 0.1922 - val_acc: 0.9461\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1384 - acc: 0.9595 - val_loss: 0.1922 - val_acc: 0.9461\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model and record the history\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-05b48545aa76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy based on the training/optimization history\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Epoch', fontsize=15)\n",
    "ax1.set_ylabel('Accuracy', color='g', fontsize=15)\n",
    "ax1.plot(history.history['accuracy'], 'g--', label='Training Accuracy')\n",
    "ax1.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# also plot the loss\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.set_ylabel('Loss', color='b', fontsize=15) \n",
    "ax2.plot(history.history['loss'], 'b:',label='Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "fig.legend(loc='center', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the model prediction \"before\" training\n",
    "pred = model(np.array(x_train[random_digit:random_digit+1], dtype=np.float32))\n",
    "\n",
    "# Plot the predicted probability distribution\n",
    "plt.bar(label, pred[0]) \n",
    "plt.xticks(label) \n",
    "plt.xlabel('Digit Classification')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Optimizers for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compile(optimizer):\n",
    "    \n",
    "    # Use the same network topology as last week\n",
    "    model = keras.Sequential([ keras.layers.Flatten(input_shape=(28, 28)), \n",
    "                          keras.layers.Dense(128, activation='relu'),\n",
    "                          keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "    # compile the model with a cross-entropy loss and specify the given optimizer\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers\n",
    "\n",
    "Optimizers arguments: [***Optimizers***](https://keras.io/api/optimizers/) in Keras\n",
    "\n",
    "SGD Class: [***SGD***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "SGD Class: [***Nesterov***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "RMSprop Class: [***RMSprop***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Adam Class: [***Adam***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Adadelta Class: [***Adadelta***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Adagrad Class: [***Adagrad***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Adamax Class: [***Adamax***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Nadam Class: [***Nadam***](https://keras.io/api/models/model_training_apis/) in Keras\n",
    "\n",
    "Ftrl Class: [***Ftrl***](https://keras.io/api/models/model_training_apis/) in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an array of the different optimizers to iterate over in a for loop\n",
    "optimizer_names = ['SGD','Momentum','Nesterov', 'RMSprop','Adagrad','Adam','NAdam']\n",
    "optimizer_list = ['SGD',keras.optimizers.SGD(learning_rate=0.01, momentum=0.5, nesterov=False),keras.optimizers.SGD(learning_rate=0.01, momentum=0.5, nesterov=True), 'RMSprop','Adagrad','Adam','NAdam']\n",
    "\n",
    "# Arrays for training and validation performance\n",
    "hist_acc = []\n",
    "hist_val_acc = []\n",
    "hist_loss = []\n",
    "hist_val_loss = []\n",
    "\n",
    "# Iterate over optimizers and train the network, using x_test and y_test as a validation set in each epoch\n",
    "for name,item in zip(optimizer_names, optimizer_list):\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    print(\"Training the ANN with %s optimizer\" %str(name))\n",
    "    \n",
    "    # Get the model from our function above\n",
    "    model = build_compile(item)\n",
    "    \n",
    "    # Train the model\n",
    "    seqModel = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test))\n",
    "    \n",
    "    # Store the performance\n",
    "    hist_acc.append(seqModel.history['accuracy'])\n",
    "    hist_val_acc.append(seqModel.history['val_accuracy'])\n",
    "    hist_loss.append(seqModel.history['loss'])\n",
    "    hist_val_loss.append(seqModel.history['val_loss'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "# summarize history for accuracy on training set\n",
    "plt.subplot(221)\n",
    "for i in range(len(optimizer_list)):\n",
    "    plt.plot(hist_acc[i],'-o',label=str(optimizer_names[i]))\n",
    "plt.title('model accuracy on training set')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# summarize history for accuracy on test set\n",
    "plt.subplot(222)\n",
    "for i in range(len(optimizer_list)):\n",
    "    plt.plot(hist_val_acc[i],'-o', label=str(optimizer_names[i]))\n",
    "plt.title('model accuracy on testing set')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# summarize history for loss on training set\n",
    "plt.subplot(223)\n",
    "for i in range(len(optimizer_list)):\n",
    "    plt.plot(hist_loss[i],'-o',label=str(optimizer_names[i]))\n",
    "plt.title('model loss on training set')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# summarize history for loss on test set\n",
    "plt.subplot(224)\n",
    "for i in range(len(optimizer_list)):\n",
    "    plt.plot(hist_val_loss[i],'-o', label=str(optimizer_names[i]))\n",
    "plt.title('model loss on testing set')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks API: [***Callbacks***](https://keras.io/api/callbacks/) in Keras\n",
    "\n",
    "EarlyStopping Class: [***EarlyStopping***](https://keras.io/api/callbacks/early_stopping/) in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with early stopping\n",
    "model_es = keras.Sequential([keras.layers.Flatten(input_shape=(28, 28)), \n",
    "                      keras.layers.Dense(128, activation='relu'),\n",
    "                      keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "# Compile the model and optimize with adam\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "model_es.compile(optimizer='Adam', loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the data while providing a validation set for each epoch\n",
    "history_es = model_es.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge (L2) Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer weight regularizers: [***Layer weight regularizers***](https://keras.io/api/layers/regularizers/) in Keras\n",
    "\n",
    "L2 Class: [***L2 class***](https://keras.io/api/layers/regularizers/#L2class) in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with an L2 regularization added to all weights\n",
    "\n",
    "model_l2 = keras.Sequential([keras.layers.Flatten(input_shape=(28, 28)), \n",
    "                      keras.layers.Dense(128, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "                      keras.layers.Dense(10, activation='softmax',kernel_regularizer=keras.regularizers.l2(0.001))])\n",
    "\n",
    "model_l2.summary()\n",
    "\n",
    "# Compile the model and optimize with adam\n",
    "model_l2.compile(optimizer='Adam', loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the data while providing a validation set for each epoch\n",
    "history_l2 = model_l2.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout Layer: [***Dropout***](https://keras.io/api/layers/regularization_layers/dropout/) in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout\n",
    "\n",
    "# Build the model with dropout\n",
    "model_dropout = keras.Sequential([keras.layers.Flatten(input_shape=(28, 28)), \n",
    "                      keras.layers.Dense(128, activation='relu'),\n",
    "                      keras.layers.Dropout(.2),\n",
    "                      keras.layers.Dense(10, activation='softmax'),\n",
    "                      keras.layers.Dropout(.2)])\n",
    "\n",
    "model_dropout.summary()\n",
    "\n",
    "# Compile the model and optimize with adam\n",
    "model_dropout.compile(optimizer='Adam', loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the data while providing a validation set for each epoch\n",
    "history_dropout = model_dropout.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting the accuracy curve for the cases of ridge regression, early stopping and dropout\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(hist_val_acc[0],'-o', label='Standard')\n",
    "plt.plot(history_l2.history['val_accuracy'],'-o', label=\"Ridge Regularization\")\n",
    "plt.plot(history_es.history['val_accuracy'],'-o', label=\"Early Stopping\")\n",
    "plt.plot(history_dropout.history['val_accuracy'],'-o', label=\"Dropout\")\n",
    "plt.title('model accuracy on test')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
