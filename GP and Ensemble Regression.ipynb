{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression\n",
    "\n",
    "Function: [***GaussianProcessRegressor***](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html) in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "\n",
    "#  Input: X; observations: y\n",
    "X = np.atleast_2d([1, 2, 3, 5, 7, 9]).T\n",
    "y = (X*np.sin(X)).ravel()\n",
    "\n",
    "# 1D mesh the input space \n",
    "x = np.atleast_2d(np.linspace(0, 10, 1000)).T\n",
    "fx = x * np.sin(x)\n",
    "\n",
    "# Build a Gaussian Process model using a customized kernel and fit the data\n",
    "kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "gp_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp_model.fit(X, y)\n",
    "\n",
    "model_name = \"Gaussian Process\"\n",
    "\n",
    "# Make the prediction on the meshed x-axis \n",
    "y_pred, sigma = gp_model.predict(x, return_std=True)\n",
    "\n",
    "\n",
    "def make_plot(X, y, y_pred, sigma, x, fx):\n",
    "    # Plot the function, the prediction and the 95% confidence interval from GP\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(x, fx, 'k:', label='$f(x) = x\\,\\sin(x)$')\n",
    "    plt.plot(X, y, 'r*', markersize=8, label='Observations')\n",
    "    plt.plot(x, y_pred, 'g-', label=model_name+' Prediction')\n",
    "    plt.fill(np.concatenate([x, x[::-1]]),\n",
    "             np.concatenate([y_pred - 1.96 * sigma, (y_pred + 1.96 * sigma)[::-1]]),\n",
    "             alpha=.4, fc='c', ec='None', label='95% Confidence Interval')\n",
    "    plt.xlabel('$x$', fontsize=16)\n",
    "    plt.ylabel('$f(x)$', fontsize=16)\n",
    "    plt.xlim(0, 10)\n",
    "    plt.ylim(-10, 15)\n",
    "    plt.legend(loc='upper left')\n",
    "    return\n",
    "\n",
    "make_plot(X, y, y_pred, sigma, x, fx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE NOISY CASE\n",
    "\n",
    "X = np.linspace(0.1, 9.9, 20)\n",
    "X = np.atleast_2d(X).T\n",
    "\n",
    "# Observations and noise\n",
    "y = (X*np.sin(X)).ravel()\n",
    "dy = 0.5 + 1 * np.random.random(y.shape)\n",
    "\n",
    "# Define the noise\n",
    "np.random.seed(1)\n",
    "noise = np.random.normal(0, dy)\n",
    "y += noise\n",
    "\n",
    "# Build a Gaussian Process model using the same kernel and fit the data\n",
    "gp_model = GaussianProcessRegressor(kernel=kernel, alpha=dy ** 2, n_restarts_optimizer=10)\n",
    "gp_model.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis \n",
    "y_pred, sigma = gp_model.predict(x, return_std=True)\n",
    "\n",
    "# Plot the results\n",
    "make_plot(X, y, y_pred, sigma, x, fx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: [***SVM***](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm) in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Build SVR regression models using four types of kernels\n",
    "l_svr = SVR(kernel='linear', C=100, gamma='auto')\n",
    "p_svr = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1, coef0=1)\n",
    "g_svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "t_svr = SVR(kernel='sigmoid', C=100, coef0=2)\n",
    "\n",
    "svrs = [l_svr, p_svr, g_svr, t_svr]\n",
    "label = ['Linear', 'Polynomial', 'Gaussian', 'tanh']\n",
    "color = ['b', 'g', 'c', 'm']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,6), nrows=1, ncols=4, sharey=True)\n",
    "\n",
    "# Use the same dataset as above for the fitting\n",
    "for i, svr in enumerate(svrs):\n",
    "    # Plot the fitted model\n",
    "    ax[i].plot(X, svr.fit(X, y).predict(X), ls=':', lw=2, color=color[i], label='{} kernel'.format(label[i]))\n",
    "    # Plot the support vectors (SVs)\n",
    "    ax[i].scatter(X[svr.support_], y[svr.support_], facecolor=\"none\", edgecolor=color[i], s=50, label='{} SVs'.format(label[i]))\n",
    "    # Plot the other data (non-support vectors)\n",
    "    ax[i].scatter(X[np.setdiff1d(np.arange(len(X)), svr.support_)], y[np.setdiff1d(np.arange(len(X)), svr.support_)], \n",
    "                      facecolor=color[i], edgecolor=\"k\", s=50, label='other training data')\n",
    "    # Plot a legend box\n",
    "    ax[i].legend(loc='upper left', bbox_to_anchor=(0., 1.),ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "fig.suptitle(\"Support Vector Regression using four kernels\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced dataset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# create Gaussian-distributed unbalanced dataset\n",
    "n = [1000, 100]\n",
    "mean = np.array([[-1.0, 0.0], [3,3]])\n",
    "cov = np.diag([2,4]) * [1.5, 0.25]\n",
    "\n",
    "x_1 = np.random.multivariate_normal(mean[0], cov, n[0])\n",
    "x_2 = np.random.multivariate_normal(mean[1], cov, n[1])\n",
    "X_unb = np.vstack((x_1, x_2))\n",
    "y_unb = np.repeat([0,1],n)\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "clf = svm.SVC(kernel=\"linear\", C=1.0)\n",
    "clf.fit(X_unb, y_unb)\n",
    "\n",
    "# fit the model using class weights\n",
    "wclf = svm.SVC(kernel=\"linear\", class_weight={1: 10})\n",
    "wclf.fit(X_unb, y_unb)\n",
    "\n",
    "# plot the samples\n",
    "plt.scatter(X_unb[:, 0], X_unb[:, 1], c=y_unb, cmap=plt.cm.Paired, edgecolors=\"k\")\n",
    "\n",
    "# get reference to axes and axes limits\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create mesh grid of points\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "# get the separating hyperplane\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "a = ax.contour(XX, YY, Z, colors=\"k\", levels=[0], alpha=0.5, linestyles=[\":\"])\n",
    "\n",
    "# get the separating hyperplane for weighted classes\n",
    "Z = wclf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins for weighted classes\n",
    "b = ax.contour(XX, YY, Z, colors=\"r\", levels=[0], alpha=0.5, linestyles=[\"-\"])\n",
    "ax.set_title(\"Support Vector Machine on unbalanced dataset\", fontsize=16)\n",
    "ax.legend(\n",
    "    [a.collections[0], b.collections[0]],\n",
    "    [\"unweighted\", \"weighted\"],\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(0., 1.0),\n",
    "    ncol=1,\n",
    "    fancybox=True,\n",
    "    shadow=True\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning Models for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: [***XGBRegressor***](https://xgboost.readthedocs.io/en/stable/python/python_api.html) in XGBoost (scikit-learn wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost for regression\n",
    "import xgboost as xgb\n",
    "model_name = \"XGBoost\"\n",
    "\n",
    "# Build a XGBoost model and fit the data\n",
    "xgb_model = xgb.XGBRegressor(n_jobs=3)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis \n",
    "y_pred = xgb_model.predict(x)\n",
    "\n",
    "sigma = np.zeros(sigma.shape)\n",
    "# Plot the results\n",
    "make_plot(X, y, y_pred, sigma, x, fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: [***RandomForestRegressor***](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest for regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_name = \"Random Forest\"\n",
    "\n",
    "# Build a random forest model and fit the data\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis \n",
    "y_pred = rf_model.predict(x)\n",
    "\n",
    "sigma = np.zeros(sigma.shape)\n",
    "# Plot the results\n",
    "make_plot(X, y, y_pred, sigma, x, fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Ensemble Learning Models for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module: [***Ensemble***](https://scikit-learn.org/stable/modules/ensemble.html) in scikit-learn\n",
    "\n",
    "Functions: [***DecisionTreeRegressor***](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html), [***RandomForestRegressor***](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), [***AdaBoostRegressor***](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html), [***GradientBoostingRegressor***](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "reg_models = (DecisionTreeRegressor(),\n",
    "              RandomForestRegressor(),\n",
    "              AdaBoostRegressor(),\n",
    "              GradientBoostingRegressor(),\n",
    "              xgb.XGBRegressor(n_jobs=3))\n",
    "\n",
    "reg_models = (reg.fit(X, y) for reg in reg_models)\n",
    "\n",
    "# title for the plots\n",
    "titles = ('Decision Tree Regressor',\n",
    "          'Random Forest',\n",
    "          'AdaBoost',\n",
    "          'Gradient Boosting',\n",
    "          'XGBoost')\n",
    "    \n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(28,4.5))\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "# set the step size of the mesh grid as h\n",
    "h = 0.02\n",
    "\n",
    "for model, title, ax in zip(reg_models, titles, axes):\n",
    "    y_pred = model.predict(x)\n",
    "    ax.plot(x, fx, 'k:', label='$f(x) = x\\,\\sin(x)$')\n",
    "    ax.plot(X, y, 'r*', markersize=8, label='Observations')\n",
    "    ax.plot(x, y_pred, 'c-', label=title+' Prediction')\n",
    "    ax.set_xlabel('$x$', fontsize=16)\n",
    "    ax.set_ylabel('$f(x)$', fontsize=16)\n",
    "    ax.set_xlim(0,10)\n",
    "    ax.set_ylim(-10, 15)\n",
    "    ax.legend(loc='upper left')    \n",
    "    ax.set_title(title, fontsize=18)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
